<!DOCTYPE html>
<html lang="en">
<head>
  
    <title>Generalities on Recurrent Neural Networks and image captioning application :: Milan&#39;s Blog</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="The main goal of RNN is to deal with sequential data as it can easily handle long-term dependencies and order. Vanilla RNNs use backpropagation but suffer from vanishing gradients by multiplying over and over by a same factor:
Therefore, we use LSTM to manage the vanishing gradient issue by changing the cell architecture. RNN are widely used for text,image generation, and text translation but also image captioning which is what interests us in this lab ." />
<meta name="keywords" content=", " />
<meta name="robots" content="noodp" />
<link rel="canonical" href="https://foglia-m.github.io/blog/posts/rnn/" />




<link rel="stylesheet" href="https://foglia-m.github.io/blog/assets/style.css">






<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://foglia-m.github.io/blog/img/apple-touch-icon-144-precomposed.png">

  <link rel="shortcut icon" href="https://foglia-m.github.io/blog/img/favicon/orange.png">



<meta name="twitter:card" content="summary" />

  
    <meta name="twitter:site" content="" />
  
    <meta name="twitter:creator" content="Milan" />



<meta property="og:locale" content="en" />
<meta property="og:type" content="article" />
<meta property="og:title" content="Generalities on Recurrent Neural Networks and image captioning application :: Milan&#39;s Blog">
<meta property="og:description" content="Implementing LSTM to deal with sequential data in image captioning" />
<meta property="og:url" content="https://foglia-m.github.io/blog/posts/rnn/" />
<meta property="og:site_name" content="Generalities on Recurrent Neural Networks and image captioning application" />

  <meta property="og:image" content="https://foglia-m.github.io/blog/">

<meta property="og:image:width" content="2048">
<meta property="og:image:height" content="1024">













</head>
<body class="orange">


<div class="container full headings--one-size">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="/blog">
  <div class="logo">
     Computer Vision, HCI and other cool topics
  </div>
</a>

    </div>
    <div class="menu-trigger">menu</div>
  </div>
  
</header>


  <div class="content">
    
<div class="post">
  <h1 class="post-title">
    <a href="https://foglia-m.github.io/blog/posts/rnn/">Generalities on Recurrent Neural Networks and image captioning application</a></h1>
  <div class="post-meta">
    
    
    <span class="post-author">:: Milan</span>
    
  </div>

  
  <span class="post-tags">
    
    #<a href="https://foglia-m.github.io/blog/tags/"></a>&nbsp;
    
    #<a href="https://foglia-m.github.io/blog/tags/"></a>&nbsp;
    
  </span>
  

  

  

  <div class="post-content"><div>
        <p>The main goal of RNN is to deal with sequential data as it can easily handle long-term dependencies and order.
Vanilla RNNs use backpropagation but suffer from vanishing gradients by multiplying over and over by a same factor:</p>
<p><img src="/blog/vanish.jpg" alt="vanish"></p>
<p>Therefore, we use LSTM to manage the vanishing gradient issue by changing the cell architecture.
RNN are widely used for text,image generation, and text translation but also image captioning which is what interests us in this lab .  Other applications are also possible such as hand gestures recognition.
image captioning which deals with important aspects of RNN such as attention, as it must implement convolutional feature extraction on the image.</p>
<p>In this lab, we implement an image captioning model based on the following pipeline:</p>
<p><img src="/blog/imcap.jpg" alt="pipeline"></p>
<p>We take an image as input and extract features using CNN (Inception), then we feed those features to a RNN (a LSTM) in order to generate captions as a word by word generation. We used the COCO 2014 dataset for training.</p>
<p>Dataset description and pre-processing : goal here is to understand the structure of the dataset and then pre-process the data so that the model can take it as a standardized input.
Encoder: we use Inception  pre trained with ImageNet as a CNN encoder (because we’re dealing with images as input and need to extract features from it).
Decoder: LSTM and Encoder-Decoder model linking the CNN model to the LSTM
Training: we train the model on the COCO 2014 dataset but because of the running time, we could not extract features from the dataset using our CNN so we used pickle to load pre-extracted features to work on.
Inference: We use our model to see how it generalizes on the test set.
Here is the github link to my ipynb file explaining and running the lab:
<a href="https://github.com/Foglia-m/IA/blob/main/RNN_icap_lab">https://github.com/Foglia-m/IA/blob/main/RNN_icap_lab</a></p>
<p>We can say that the global outline of RNN implementation is very close to simple machine learning (or even deep learning) tasks such as classification and regression using FFNN and CNN. Here the tricky part is to correctly understand how the input works as it’s sequential data and how the different models (coder and encoder) are merged into a unified model called the coder-encoder which performs the whole process. Also, sequential data such as words requires to deal with vocabularies (for padding and also mapping purposes) which is of course  linked to the tricky aspect of the input.</p>
<p>What is so interesting about RNNs?
RNNs always have some kind of magical aspect because of the data generation, whether it is text or images, but it showcases all its potential with video games AI applications for complex games such as RTS (Starcraft, AOE) by working along with reinforcement learning such as Q learning. Here, the attention is at the core of the problem since the AI has to deal with many complex and different data so instead of basic RNN, attention based models called transformers are used here (they’re also used in Natural Language Processing as they provide much better results).</p>
<p>The idea that mostly intrigues me is to beat a player only using learned strategy and also spontaneous tactics instead of using a huge amount of APM (action per minute) which makes it a boring fast-computer asset.
We know that the best pro gamers have a mean of more than 400 APM. Here we can see what APM are the current best AI using, we can see that it’s quite fitting the standards pro gaming APM.</p>
<p><img src="/blog/meanapm.jpg" alt="meanapm"></p>

      </div></div>

  
  
<div class="pagination">
    <div class="pagination__title">
        <span class="pagination__title-h">Read other posts</span>
        <hr />
    </div>
    <div class="pagination__buttons">
        
        <span class="button previous">
            <a href="https://foglia-m.github.io/blog/posts/blender/">
                <span class="button__icon">←</span>
                <span class="button__text">Blender or best UI I&#39;ve seen for 3D modelization</span>
            </a>
        </span>
        
        
        <span class="button next">
            <a href="https://foglia-m.github.io/blog/posts/wbsports/">
                <span class="button__text">Golf Ball Automated Sorting and Automation project</span>
                <span class="button__icon">→</span>
            </a>
        </span>
        
    </div>
</div>

  

  

</div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2020 Powered by <a href="http://gohugo.io">Hugo</a></span>
    
        <span>:: Theme made by <a href="https://twitter.com/panr">panr</a></span>
      </div>
  </div>
</footer>

<script src="https://foglia-m.github.io/blog/assets/main.js"></script>
<script src="https://foglia-m.github.io/blog/assets/prism.js"></script>





  
</div>

</body>
</html>
